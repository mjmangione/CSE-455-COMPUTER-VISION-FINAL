## Classifying Species of Birds Using Transfer Learning
For this assignment we were given a working classifier to test and improve its accuracy in classifying different species of birds. We trained on a 60,000 image dataset of 555 different species. Our goal was to increase the accuracy of our model upon a separate, unlabeled test dataset, which is evaluated and ranked by the associated Kaggle compitition leaderboard. Our final network succeeded in correctly identifying 81.55% of all birds in the test images.

#### Inherited Code
The model we were given was around 50% accurate on the test data, which gave us plenty of room to improve. Alongside the working model, functions were given to load and configure the datasets, as well as evaluate and save the final predictions in a csv file. The code provided also outlined many hyperparameters for fine-tuning the classfier, such as the learning rate, momentum and batch size. The original code was based upon the ResNet-18 model architecture, pre-trained on ImageNet.

#### Transfer Learning Models
The first, and largest, improvement in model accuracy came from utilizing a different pre-trained convolutional neural network architecture. ResNet-18 is efficient and lightweight, but many better models have been released since its debut. First, I scaled up; I switched ResNet-18 for Res-Net34. This already made a large difference. Due to the positive feedback, I decided to continue up-scaling the network. I tried to use many but ran into various problems with size and reliability. For example, I was enticed to use EfficientNet for its impressive test-accuracy on ImageNet, but the best model (B7) was too large for my hardware. The largest one I could run was EfficientNet-B3, which then had severe issues adapting to our dataset. The most complex architecture successfully implemented was ResNeXt-101, a larger continuation ofthe ResNet series with group convolutions added.

#### Video RAM Limitations
Because I chose to work on Kaggle, I was faced with several aggravating constraints to my time and scale. With a lot of time needed to test and configure different models, a 38 hour limit on GPU time becomes a lot more worrysome (especially when I accidently leave my Kaggle Notebook open overnight). However, more pressing was the 16GB video RAM limit for my project. It is better than my own device, but it deeply limited the scale of my project. I wanted to increase the resolution of the training images, but the already-large dataset was too big to successfully load it, let alone with a powerful pre-trained network to match it. Similarly, even with the small (128 x 128 pixel) images, there wasn't enough space to also load top-tier models that I wanted. I felt I was at my limit.

However, eventually I came across the HDF5 data format and the compression it offered. I realized I could convert the bird image datasets into this compressed format, and still have space to load it on complex models. Previously, I did not have enough space to even increase the resolution to 164 x 164 pixels per image. With the compression, however, I could use up to 224 x 224 pixel images. While it is still a small photo size, it nearly triples the amounts of inputs to total pixels, i.e., the number of inputs to the neural network. Despite the improvement in storage, there still remained the trade-off between image size and complexity of the model. To work on the larger images, I needed to scale down from ResNeXt-101 to its 50 layer counterpart. I experimented with several different combinations of image size and model complexity, but I could not escape this interaction.

#### Results
In the end, I settled with the ResNeXt-50 pre-trained model on the 224 x 224 pixel images, as I felt it was the strongest equilibrium between the model complexity and image size. Besides for these parameters, I engaged in plenty of other fine-tuning to optimize the success of the network. I found that lowering the batch size produces slightly better results. Similarly, I let the model train over 12 epoches, utilizing a learning-rate schedule that gradually decreases, as described in the tutorial. This set up produced my highest accuracy, correctly identifying 81.55% of all birds in the test images. Given that the dataset includes 555 different species, I am pretty satisified with its results. 

I wish I could spend more time on this project but I have many other demanding assignments this week. If I had more time, I would reconsider and experiment with different number of epoches and their respective learning rates. During training, 99% of the loss function minimization occured in the first half of the schedule, and I am worried that the continued training may have lead to possible overfitting. The learning rate schedule was designed to mitigate this, but I am still curious about the effect of the prolonged training, and if I would have a more robust model without it.

